{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydicom matplotlib rt_utils scikit-learn scikit-image torch pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import required packages\n",
    "import pydicom # pydicom is a package for working with DICOM files such as medical images, reports, and radiotherapy objects\n",
    "import os # os module provides functions for interacting with the operating system\n",
    "import matplotlib.pyplot as plt # matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy\n",
    "import numpy as np # NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "from rt_utils import RTStructBuilder # rt_utils is a package for working with DICOM RT structure sets\n",
    "import re # re module provides regular expression matching operations\n",
    "from sklearn.model_selection import train_test_split # sklearn.model_selection is a module for splitting arrays or matrices into random train and test subsets\n",
    "import numpy as np # for working with arrays\n",
    "from skimage.transform import resize # for resizing images\n",
    "import copy # for copying objects\n",
    "import torch \n",
    "import cv2 # for working with images\n",
    "import shutil # for working with files and collections of files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata.csv') # this loads the csv file into metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RTstructT1' 'RTstructT2FS' 'RTstructAlignedT1toPET'\n",
      " 'RTstructAlignedT2FStoPET' 'AlignedT1toPETBOX' 'RTstructPET' 'PET AC'\n",
      " 'AXIAL SE T2 FAT SAT - RESEARCH' 'RTstructCT' 'AlignedT2FStoPETBOX'\n",
      " 'AllignedT1toPETBOX' 'RTstructAlignedSTIRtoPET' 'AXIAL SE T1 - RESEARCH'\n",
      " 'AlignedSTIRtoPETBOX' 'WB2DAC' 'AXT1' 'RTstructSTIR' 'STIR longTE AX'\n",
      " 'PED2DAC' 'AX STIR' 'AX T1' 'T2ST RT - RESEARCH' 'T1 RT - RESEARCH'\n",
      " 'AXIALT1' 'RTstructAlignedTtoPET' 'AX. T2 FSE  FS - RESEARCH'\n",
      " 'AX. T1 SE - RESEARCH' 'Axial T1 - RESEARCH' 'PET AC 21'\n",
      " 'T1 AX - RESEARCH' 'STIR AX - RESEARCH' 'CT IMAGES - RESEARCH' 'LEGS2DAC'\n",
      " 'Axial T1 UPPER - RESEARCH' 'Axial FSET2 FS UPPER'\n",
      " '2. AXIAL T1 BOTH LEGS - RESEARCH' '3. AXIAL STIR - RESEARCH'\n",
      " 'sag FSET2 Fatsat' 'Sagittal T1' '4. AXIAL  T1' '5. AXIAL T2 F.S.'\n",
      " 'StandardFull' 'RTstructAlignedT1toPETBOX' 'RTstructAlignedSTIRtoPETBOX'\n",
      " 'T2ST LT - RESEARCH' 'T1 LT - RESEARCH' 'CT IMAGES - LEGS - RESEARCH'\n",
      " 'AXIAL FRFSE T2 Fatsat - RESEARCH' 'AXIAL FSE T1 - RESEARCH' 'O AX T1'\n",
      " 'AX STIR iPAT - RESEARCH' 'AX TSE T1 IPAT - RESEARCH' 'AX  STIR'\n",
      " 'StandardFull - RESEARCH' 'HIPT2TURBOSTIRRAPIDE - RESEARCH'\n",
      " 'HIPT1TRASE - RESEARCH' 'AXIAL FSE T1 PELVIS'\n",
      " 'AXIAL FRFSE T2 Fatsat Pelvis' 'AX FSE T1 - RESEARCH'\n",
      " 'AX FSE T2 FS - RESEARCH' 'Coronal FSET1' 'Coronal Fast Stir'\n",
      " 'CT IMAGES - ARMS - RESEARCH' 'AX. STIR HAUT' 'Ax T1 HAUT'\n",
      " 'AX STIR BILAT' 'COR TSE T1' 'COR STIR' 'AX T1 FSE BILAT' 'T1 LT'\n",
      " 'T2ST LT' 'AX TSE T1 - RESEARCH' 'SAG  STIR - RESEARCH'\n",
      " 'Coronal Fast Stir - RESEARCH' 'Axial FSET2 Fatsat - RESEARCH'\n",
      " 'Coronal FSET1 - RESEARCH' 'Axial T1  LT THIGH'\n",
      " 'Axial T1 RT UPPER - RESEARCH' 'Axial T2 FS RT LOWER - RESEARCH'\n",
      " 'Axial T1 RT HIP THIGH' 'Axial T2 FS RT HIPTHIGH'\n",
      " 'Axial FSET2 FS ONLY TUMOR - RESEARCH' 'Axial T1 ONLY TUMOR - RESEARCH'\n",
      " 'Axial FSET1 - RESEARCH' 'AXIAL STIR' 'AXIAL  SE T1' 'AX STIR - RESEARCH'\n",
      " 'AX  T1 - RESEARCH' 'AXIAL T1 - RESEARCH'\n",
      " 'StandardFull - CT LEGS - RESEARCH' 'AXIAL FSE T2 - RESEARCH' 'AX TSE T1'\n",
      " 'T2SP LT - RESEARCH' 'eSTIRlongTE SENSE W PICT-PLUS'\n",
      " 'eT1WTSEax SENSE W PICT-PLUS' '2-AX  Stir irFSE H  DRT - RESEARCH'\n",
      " 'CT IMAGES - BODY RESEARCH' '3-AX  T1 SE DRT - RESEARCH'\n",
      " 'Axial FSET2 Fatsat' 'AX T1 - RESEARCH' 'AX IR - RESEARCH' 'Axial T1'\n",
      " 'AX. T2 FSE FS - RESEARCH' '3- O-AXI FAT T2 - RESEARCH'\n",
      " '2- AXIAL T1 - RESEARCH' 'CT IMAGES - BODY - RESEARCH' 'RTStructPET'\n",
      " 'RTStructCT' 'KNEE       AX T1' 'KNEE       AXT2SP' 'Axial FSET1'\n",
      " 'Axial FSET2 Fatsat LOWER TIB FIB - RESEARCH'\n",
      " 'Axial FSET1 LOWER TIB FIB - RESEARCH' 'CT IMAGES'\n",
      " 'AXI T1 FSE - RESEARCH' 'AXIAL  FSE T2 FATSAT - RESEARCH'\n",
      " 'AXIAL  T1- RESEARCH' 'AXIALT2 FSE FS']\n"
     ]
    }
   ],
   "source": [
    "# return all the values in Series Description column\n",
    "print(metadata['Series Description'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head() # Show the first 5 rows of the metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Inspection\n",
    "total_images = metadata['Number of Images'].sum()\n",
    "# total number of series is the number of rows in the metadata dataframe \n",
    "total_series = metadata.shape[0]\n",
    "\n",
    "series_per_subject = metadata['Subject ID'].value_counts()\n",
    "# sort in ascending order of subject ID\n",
    "series_per_subject = series_per_subject.sort_index()\n",
    "\n",
    "series_per_modality = metadata['Modality'].value_counts()\n",
    "images_per_subject = metadata.groupby('Subject ID')['Number of Images'].sum()\n",
    "# sort in ascending order of subject ID\n",
    "images_per_subject = images_per_subject.sort_index()\n",
    "\n",
    "images_per_modality = metadata.groupby('Modality')['Number of Images'].sum()\n",
    "\n",
    "print('Total number of images: ', total_images)\n",
    "print('Total number of series: ', total_series)\n",
    "print('Number of series per subject: \\n', series_per_subject)\n",
    "print('Number of series per modality: \\n', series_per_modality)\n",
    "print('Number of images per subject: \\n', images_per_subject)\n",
    "print('Number of images per modality: \\n', images_per_modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of number of series UID for each subject ID\n",
    "plt.figure(figsize=(10, 6))\n",
    "series_per_subject.plot(kind='bar')\n",
    "plt.title('Number of Series UID for Each Subject ID')\n",
    "plt.xlabel('Subject ID')\n",
    "plt.ylabel('Number of Series UID')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of number of images for each subject ID\n",
    "plt.figure(figsize=(10, 6))\n",
    "images_per_subject.plot(kind='bar')\n",
    "plt.title('Number of Images for Each Subject ID')\n",
    "plt.xlabel('Subject ID')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of number of images for each modality\n",
    "plt.figure(figsize=(10, 6))\n",
    "images_per_modality.plot(kind='bar')\n",
    "plt.title('Number of Images for Each Modality')\n",
    "plt.xlabel('Modality')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of number of Series UID for each modality\n",
    "plt.figure(figsize=(10, 6))\n",
    "series_per_modality.plot(kind='bar')\n",
    "plt.title('Number of Series UID for Each Modality')\n",
    "plt.xlabel('Modality')\n",
    "plt.ylabel('Number of Series UID')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell replaces the series description with \"STIR\", \"T1toPET\", \"T2FStoPET\", \"CT\", \"PET\", \"T1\", \"T2\", \"DAC\" for easier pairing of RTStruct with its corresponding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to modify the series description\n",
    "def modify_series_description(series_description):\n",
    "    if \"STIRtoPET\" in series_description:\n",
    "        return \"STIRtoPET\"\n",
    "    elif \"STIR\" in series_description:\n",
    "        return \"STIR\"\n",
    "    elif \"Stir\" in series_description:\n",
    "        return \"STIR\"\n",
    "    elif \"AX IR\" in series_description:\n",
    "        return \"STIR\"\n",
    "    elif \"T1toPET\" in series_description:\n",
    "        return \"T1toPET\"\n",
    "    elif \"T2FStoPET\" in series_description:\n",
    "        return \"T2FStoPET\"\n",
    "    elif \"TtoPET\" in series_description:\n",
    "        return \"T1toPET\"\n",
    "    elif \"PET\" in series_description:\n",
    "        return \"PET\"\n",
    "    elif \"T1\" in series_description:\n",
    "        return \"T1\"\n",
    "    elif \"T2FS\" in series_description:\n",
    "        return \"T2FS\"\n",
    "    elif \"T2 F\" in series_description:\n",
    "        return \"T2FS\"\n",
    "    elif \"FSE T2\" in series_description:\n",
    "        return \"T2FS\"\n",
    "    elif \"T2SP\" in series_description:\n",
    "        return \"T2FS\"\n",
    "    elif \"FAT T2\" in series_description:\n",
    "        return \"T2FS\"\n",
    "    elif \"T2\" in series_description:\n",
    "        return \"STIR\"\n",
    "    elif \"CT\" in series_description:\n",
    "        return \"CT\"\n",
    "    elif \"DAC\" in series_description:\n",
    "        return \"PET\"\n",
    "    elif \"Standard\" in series_description:\n",
    "        return \"CT\"\n",
    "    else:\n",
    "        return series_description  # If no match, return the original series description\n",
    "\n",
    "# Apply the function to the 'Series Description' column\n",
    "metadata['Series Description'] = metadata['Series Description'].apply(modify_series_description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell filters the metadata dataframe into its corresponding modalities (MR, CT, PT), and also concatenates the corresponding RTstructs to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include Series UID, Subject ID, Study UID, Series Description, Modality, and File Location of metadata\n",
    "metadata_filtered = metadata[['Series UID', 'Subject ID', 'Study UID', 'Series Description', 'Modality', 'File Location']]\n",
    "\n",
    "# Separate the dataframe based on the 'Modality' column\n",
    "df_MR = metadata_filtered[metadata_filtered['Modality'] == 'MR']\n",
    "df_CT = metadata_filtered[metadata_filtered['Modality'] == 'CT']\n",
    "df_PT = metadata_filtered[metadata_filtered['Modality'] == 'PT']\n",
    "df_RTSTRUCT = metadata_filtered[metadata_filtered['Modality'] == 'RTSTRUCT']\n",
    "\n",
    "# Filter RTSTRUCT rows where Study UID has a match in MR, CT, and PT dataframes and a match in Series Description\n",
    "rtstruct_mr = df_RTSTRUCT[df_RTSTRUCT['Study UID'].isin(df_MR['Study UID'])]\n",
    "rtstruct_mr = rtstruct_mr[rtstruct_mr['Series Description'].isin(df_MR['Series Description'])]\n",
    "rtstruct_ct = df_RTSTRUCT[df_RTSTRUCT['Study UID'].isin(df_CT['Study UID'])]\n",
    "rtstruct_ct = rtstruct_ct[rtstruct_ct['Series Description'].isin(df_CT['Series Description'])]\n",
    "rtstruct_pt = df_RTSTRUCT[df_RTSTRUCT['Study UID'].isin(df_PT['Study UID'])]\n",
    "rtstruct_pt = rtstruct_pt[rtstruct_pt['Series Description'].isin(df_PT['Series Description'])]\n",
    "\n",
    "# Append these RTSTRUCT rows to the corresponding dataframes\n",
    "df_MR_rtstruct = pd.concat([df_MR, rtstruct_mr])\n",
    "df_CT_rtstruct = pd.concat([df_CT, rtstruct_ct])\n",
    "df_PT_rtstruct = pd.concat([df_PT, rtstruct_pt])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each of df_MR_rtstruct, df_CT_rtstruct, df_PT_rtstruct dataframes, we group them according to their Subject ID into a suitable dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group each dataframe by 'Subject ID'\n",
    "df_MR_grouped = df_MR_rtstruct.groupby('Subject ID')\n",
    "df_CT_grouped = df_CT_rtstruct.groupby('Subject ID')\n",
    "df_PT_grouped = df_PT_rtstruct.groupby('Subject ID')\n",
    "\n",
    "# Create a dictionary where each key is a 'Subject ID' and each value is a subset of the dataframe for that subject\n",
    "df_MR_dict = {group: df for group, df in df_MR_grouped}\n",
    "df_CT_dict = {group: df for group, df in df_CT_grouped}\n",
    "df_PT_dict = {group: df for group, df in df_PT_grouped}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing and Serialisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will load the dicom images and mask from the given directory\n",
    "def load_data(dicom_dir, rtstruct_dir):\n",
    "    rtstruct_dir = os.path.join(rtstruct_dir, '1-1.dcm')\n",
    "    rtstruct = RTStructBuilder.create_from(\n",
    "    dicom_series_path=dicom_dir, \n",
    "    rt_struct_path= rtstruct_dir\n",
    "    )  # Load existing RT Struct. Requires the series path and existing RT Struct path\n",
    "\n",
    "    # print(rtstruct.get_roi_names()) # view all of the ROI names from within the image\n",
    "\n",
    "    mask_3d = rtstruct.get_roi_mask_by_name(\"GTV_Mass\") # loading the 3D Mask from within the RT Struct\n",
    "\n",
    "    image_files = [os.path.join(dicom_dir, f) for f in os.listdir(dicom_dir) if f.endswith('.dcm')] # get a list of all DICOM files in the directory\n",
    "    image_files.sort(reverse=True) # sort the image_files by their name\n",
    "    images = {pydicom.dcmread(f).SOPInstanceUID: pydicom.dcmread(f) for f in image_files} # load the DICOM images\n",
    "\n",
    "    return images, mask_3d\n",
    "\n",
    "\n",
    "# this function will display the images and mask\n",
    "def view_data(images, mask_3d):\n",
    "    for i in range(mask_3d.shape[2]):\n",
    "        uid = list(images.keys())[i]  # get the SOPInstanceUID of the ith image\n",
    "\n",
    "\n",
    "        mask_slice = mask_3d[:, :, i]\n",
    "\n",
    "        # if the mask_slice dimensions are not the same as the image dimensions, crop the side with more pixels and pad the side with less pixels with zeros\n",
    "        if mask_slice.shape != images[uid].pixel_array.shape:\n",
    "            if mask_slice.shape[0] > images[uid].pixel_array.shape[0]:\n",
    "                # crop the mask_slice\n",
    "                mask_slice = mask_slice[:images[uid].pixel_array.shape[0], :]\n",
    "            elif mask_slice.shape[0] < images[uid].pixel_array.shape[0]:\n",
    "                # pad the mask_slice with zeros starting from the bottom\n",
    "                mask_slice = np.pad(mask_slice, ((0, images[uid].pixel_array.shape[0] - mask_slice.shape[0]), (0, 0)), 'constant')\n",
    "\n",
    "            if mask_slice.shape[1] > images[uid].pixel_array.shape[1]:\n",
    "                # crop the mask_slice\n",
    "                mask_slice = mask_slice[:, :images[uid].pixel_array.shape[1]]\n",
    "            elif mask_slice.shape[1] < images[uid].pixel_array.shape[1]:\n",
    "                # pad the mask_slice with zeros from the right\n",
    "                mask_slice = np.pad(mask_slice, ((0, 0), (0, images[uid].pixel_array.shape[1] - mask_slice.shape[1])), 'constant')\n",
    "\n",
    "        # Now that the mask_slice and image dimensions are the same, we can resize the dimensions of both mask_slice and image for machine learning\n",
    "        mask_slice = cv2.resize(mask_slice.astype(np.uint8), (128, 128), interpolation=cv2.INTER_NEAREST)\n",
    "        img_slice = cv2.resize(images[uid].pixel_array, (128, 128))\n",
    "\n",
    "        plt.imshow(img_slice, cmap='gray') # plot the ith image\n",
    "        plt.imshow(mask_slice, cmap='jet', alpha=0.5) # overlay the mask with transparency\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# this function will serialise the images and mask for machine learning\n",
    "def serialise_data(images, mask_3d, img_directory, mask_directory):\n",
    "    for i in range(mask_3d.shape[2]):\n",
    "        uid = list(images.keys())[i]  # get the SOPInstanceUID of the ith image\n",
    "\n",
    "        mask_slice = mask_3d[:, :, i]\n",
    "\n",
    "        # if the mask_slice dimensions are not the same as the image dimensions, crop the side with more pixels and pad the side with less pixels with zeros\n",
    "        if mask_slice.shape != images[uid].pixel_array.shape:\n",
    "            if mask_slice.shape[0] > images[uid].pixel_array.shape[0]:\n",
    "                # crop the mask_slice\n",
    "                mask_slice = mask_slice[:images[uid].pixel_array.shape[0], :]\n",
    "            elif mask_slice.shape[0] < images[uid].pixel_array.shape[0]:\n",
    "                # pad the mask_slice with zeros starting from the bottom\n",
    "                mask_slice = np.pad(mask_slice, ((0, images[uid].pixel_array.shape[0] - mask_slice.shape[0]), (0, 0)), 'constant')\n",
    "\n",
    "            if mask_slice.shape[1] > images[uid].pixel_array.shape[1]:\n",
    "                # crop the mask_slice\n",
    "                mask_slice = mask_slice[:, :images[uid].pixel_array.shape[1]]\n",
    "            elif mask_slice.shape[1] < images[uid].pixel_array.shape[1]:\n",
    "                # pad the mask_slice with zeros from the right\n",
    "                mask_slice = np.pad(mask_slice, ((0, 0), (0, images[uid].pixel_array.shape[1] - mask_slice.shape[1])), 'constant')\n",
    "\n",
    "        # Now that the mask_slice and image dimensions are the same, we can resize the dimensions of both mask_slice and image for machine learning\n",
    "        mask_slice = cv2.resize(mask_slice.astype(np.uint8), (128, 128), interpolation=cv2.INTER_NEAREST)\n",
    "        img_slice = cv2.resize(images[uid].pixel_array, (128, 128), interpolation = cv2.INTER_LANCZOS4)\n",
    "        \n",
    "        # normalise the img_slice\n",
    "        img_slice = img_slice / 255.0\n",
    "\n",
    "        # serialise the img_slice into jpg format in the img_directory\n",
    "        try:\n",
    "            cv2.imwrite(os.path.join(img_directory, f'{images[uid].SeriesInstanceUID}_{i}.png'), img_slice)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving image: {e}\")\n",
    "        \n",
    "        # serialise the mask_slice into png format in the mask_directory\n",
    "        try:\n",
    "            cv2.imwrite(os.path.join(mask_directory, f'{images[uid].SeriesInstanceUID}_{i}.png'), mask_slice*255)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving mask: {e}\")\n",
    "\n",
    "\n",
    "def split_data_into_train_val_test(dataset_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
    "    # Define the sub-directories\n",
    "    image_dir = os.path.join(dataset_dir, \"train\", \"images\")\n",
    "    mask_dir = os.path.join(dataset_dir, \"train\", \"mask\")\n",
    "\n",
    "    # Get the lists of images and masks\n",
    "    images = os.listdir(image_dir)\n",
    "    masks = os.listdir(mask_dir)\n",
    "\n",
    "    # Split the datasets into training, validation and testing sets\n",
    "    temp_images, test_images, temp_masks, test_masks = train_test_split(images, masks, test_size=test_ratio, random_state=random_state)\n",
    "    train_images, val_images, train_masks, val_masks = train_test_split(temp_images, temp_masks, test_size=val_ratio/(train_ratio+val_ratio), random_state=random_state)\n",
    "\n",
    "    # Define the destination directories\n",
    "    test_image_dest_dir = os.path.join(dataset_dir, \"test\", \"images\")\n",
    "    test_mask_dest_dir = os.path.join(dataset_dir, \"test\", \"mask\")\n",
    "    val_image_dest_dir = os.path.join(dataset_dir, \"val\", \"images\")\n",
    "    val_mask_dest_dir = os.path.join(dataset_dir, \"val\", \"mask\")\n",
    "\n",
    "    # Move the testing images and masks to the testing directory\n",
    "    for img in test_images:\n",
    "        shutil.move(os.path.join(image_dir, img), test_image_dest_dir)\n",
    "\n",
    "    for mask in test_masks:\n",
    "        shutil.move(os.path.join(mask_dir, mask), test_mask_dest_dir)\n",
    "\n",
    "    # Move the validation images and masks to the validation directory\n",
    "    for img in val_images:\n",
    "        shutil.move(os.path.join(image_dir, img), val_image_dest_dir)\n",
    "\n",
    "    for mask in val_masks:\n",
    "        shutil.move(os.path.join(mask_dir, mask), val_mask_dest_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we take all the MR images and mask from all patients (STS_001 to STS_051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for each of STS_001 to STS_051\n",
    "data_dict = {}\n",
    "\n",
    "# specify the path to the dataset\n",
    "dataset_mr_path = 'dataset_mr'\n",
    "img_path = os.path.join(dataset_mr_path, 'train', 'images')\n",
    "mask_path = os.path.join(dataset_mr_path, 'train', 'mask')\n",
    "\n",
    "# filter df_MR_dict for STS_001 to separate DCM images from RTSTRUCT\n",
    "for key, value in df_MR_dict.items():\n",
    "    img_df_MR_dict = value[value['Modality'] == 'MR']\n",
    "    rtstruct_df_MR_dict = value[value['Modality'] == 'RTSTRUCT']\n",
    "    \n",
    "    # initialise array\n",
    "    data_dict[key] = []\n",
    "    match = False # for debugging\n",
    "\n",
    "    # load the dcm and rtstruct data\n",
    "    for index, row in value.iterrows(): # iterate through each row in the dataframe of the current patient (value)\n",
    "        if row['Modality'] == 'MR': # if the current row is not an RTSTRUCT\n",
    "            for index1, row1 in value[value['Series UID'] != row['Series UID']].iterrows(): # iterate through the remaining rows in the dataframe of the current patient (value)\n",
    "                if row1['Series Description'] == row['Series Description']: # if the current row is the corresponding RTSTRUCT to the current MR image\n",
    "                    data_dict[key].append(load_data(row['File Location'], row1['File Location'])) # load the data and append it to the array\n",
    "                    match = True # for debugging\n",
    "                    break # break out of the loop\n",
    "            if match == False: # for debugging\n",
    "                raise Exception('no match found for ' + row['Series UID']) # for debugging\n",
    "            match = False # for debugging\n",
    "    \n",
    "    # serialise the data\n",
    "    for i in range(len(data_dict[key])):\n",
    "        serialise_data(data_dict[key][i][0], data_dict[key][i][1], img_path, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_into_train_val_test(dataset_mr_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmimaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
