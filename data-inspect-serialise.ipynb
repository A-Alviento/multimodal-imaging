{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydicom matplotlib rt_utils scikit-learn scikit-image torch pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import required packages\n",
    "import pydicom # pydicom is a package for working with DICOM files such as medical images, reports, and radiotherapy objects\n",
    "import os # os module provides functions for interacting with the operating system\n",
    "import matplotlib.pyplot as plt # matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy\n",
    "import numpy as np # NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "from rt_utils import RTStructBuilder # rt_utils is a package for working with DICOM RT structure sets\n",
    "import re # re module provides regular expression matching operations\n",
    "from sklearn.model_selection import train_test_split # sklearn.model_selection is a module for splitting arrays or matrices into random train and test subsets\n",
    "import numpy as np # for working with arrays\n",
    "from skimage.transform import resize # for resizing images\n",
    "import copy # for copying objects\n",
    "import torch \n",
    "import cv2 # for working with images\n",
    "import shutil # for working with files and collections of files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata.csv') # this loads the csv file into metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head() # Show the first 5 rows of the metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Inspection\n",
    "total_images = metadata['Number of Images'].sum()\n",
    "# total number of series is the number of rows in the metadata dataframe \n",
    "total_series = metadata.shape[0]\n",
    "\n",
    "series_per_subject = metadata['Subject ID'].value_counts()\n",
    "# sort in ascending order of subject ID\n",
    "series_per_subject = series_per_subject.sort_index()\n",
    "\n",
    "series_per_modality = metadata['Modality'].value_counts()\n",
    "images_per_subject = metadata.groupby('Subject ID')['Number of Images'].sum()\n",
    "# sort in ascending order of subject ID\n",
    "images_per_subject = images_per_subject.sort_index()\n",
    "\n",
    "images_per_modality = metadata.groupby('Modality')['Number of Images'].sum()\n",
    "\n",
    "print('Total number of images: ', total_images)\n",
    "print('Total number of series: ', total_series)\n",
    "print('Number of series per subject: \\n', series_per_subject)\n",
    "print('Number of series per modality: \\n', series_per_modality)\n",
    "print('Number of images per subject: \\n', images_per_subject)\n",
    "print('Number of images per modality: \\n', images_per_modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of number of series UID for each subject ID\n",
    "plt.figure(figsize=(10, 6))\n",
    "series_per_subject.plot(kind='bar')\n",
    "plt.title('Number of Series UID for Each Subject ID')\n",
    "plt.xlabel('Subject ID')\n",
    "plt.ylabel('Number of Series UID')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of number of images for each subject ID\n",
    "plt.figure(figsize=(10, 6))\n",
    "images_per_subject.plot(kind='bar')\n",
    "plt.title('Number of Images for Each Subject ID')\n",
    "plt.xlabel('Subject ID')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of number of images for each modality\n",
    "plt.figure(figsize=(10, 6))\n",
    "images_per_modality.plot(kind='bar')\n",
    "plt.title('Number of Images for Each Modality')\n",
    "plt.xlabel('Modality')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of number of Series UID for each modality\n",
    "plt.figure(figsize=(10, 6))\n",
    "series_per_modality.plot(kind='bar')\n",
    "plt.title('Number of Series UID for Each Modality')\n",
    "plt.xlabel('Modality')\n",
    "plt.ylabel('Number of Series UID')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell replaces the series description with \"STIR\", \"T1toPET\", \"T2FStoPET\", \"CT\", \"PET\", \"T1\", \"T2\", \"DAC\" for easier pairing of RTStruct with its corresponding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to modify the series description\n",
    "def modify_series_description(series_description):\n",
    "    if \"STIR\" in series_description:\n",
    "        return \"STIR\"\n",
    "    elif \"Stir\" in series_description:\n",
    "        return \"STIR\"\n",
    "    elif \"AX IR\" in series_description:\n",
    "        return \"STIR\"\n",
    "    elif \"T1toPET\" in series_description:\n",
    "        return \"T1toPET\"\n",
    "    elif \"T2FStoPET\" in series_description:\n",
    "        return \"T2FStoPET\"\n",
    "    elif \"CT\" in series_description:\n",
    "        return \"CT\"\n",
    "    elif \"PET\" in series_description:\n",
    "        return \"PET\"\n",
    "    elif \"T1\" in series_description:\n",
    "        return \"T1\"\n",
    "    elif \"T2\" in series_description:\n",
    "        return \"T2\"\n",
    "    elif \"DAC\" in series_description:\n",
    "        return \"DAC\"\n",
    "    elif \"Standard\" in series_description:\n",
    "        return \"DAC\"\n",
    "    else:\n",
    "        return series_description  # If no match, return the original series description\n",
    "\n",
    "# Apply the function to the 'Series Description' column\n",
    "metadata['Series Description'] = metadata['Series Description'].apply(modify_series_description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell filters the metadata dataframe into its corresponding modalities (MR, CT, PT), and also concatenates the corresponding RTstructs to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include Series UID, Subject ID, Study UID, Series Description, Modality, and File Location of metadata\n",
    "metadata_filtered = metadata[['Series UID', 'Subject ID', 'Study UID', 'Series Description', 'Modality', 'File Location']]\n",
    "\n",
    "# Separate the dataframe based on the 'Modality' column\n",
    "df_MR = metadata_filtered[metadata_filtered['Modality'] == 'MR']\n",
    "df_CT = metadata_filtered[metadata_filtered['Modality'] == 'CT']\n",
    "df_PT = metadata_filtered[metadata_filtered['Modality'] == 'PT']\n",
    "df_RTSTRUCT = metadata_filtered[metadata_filtered['Modality'] == 'RTSTRUCT']\n",
    "\n",
    "# Filter RTSTRUCT rows where Study UID has a match in MR, CT, and PT dataframes and a match in Series Description\n",
    "rtstruct_mr = df_RTSTRUCT[df_RTSTRUCT['Study UID'].isin(df_MR['Study UID'])]\n",
    "rtstruct_mr = rtstruct_mr[rtstruct_mr['Series Description'].isin(df_MR['Series Description'])]\n",
    "rtstruct_ct = df_RTSTRUCT[df_RTSTRUCT['Study UID'].isin(df_CT['Study UID'])]\n",
    "rtstruct_ct = rtstruct_ct[rtstruct_ct['Series Description'].isin(df_CT['Series Description'])]\n",
    "rtstruct_pt = df_RTSTRUCT[df_RTSTRUCT['Study UID'].isin(df_PT['Study UID'])]\n",
    "rtstruct_pt = rtstruct_pt[rtstruct_pt['Series Description'].isin(df_PT['Series Description'])]\n",
    "\n",
    "# Append these RTSTRUCT rows to the corresponding dataframes\n",
    "df_MR_rtstruct = pd.concat([df_MR, rtstruct_mr])\n",
    "df_CT_rtstruct = pd.concat([df_CT, rtstruct_ct])\n",
    "df_PT_rtstruct = pd.concat([df_PT, rtstruct_pt])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each of df_MR_rtstruct, df_CT_rtstruct, df_PT_rtstruct dataframes, we group them according to their Subject ID into a suitable dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group each dataframe by 'Subject ID'\n",
    "df_MR_grouped = df_MR_rtstruct.groupby('Subject ID')\n",
    "df_CT_grouped = df_CT_rtstruct.groupby('Subject ID')\n",
    "df_PT_grouped = df_PT_rtstruct.groupby('Subject ID')\n",
    "\n",
    "# Create a dictionary where each key is a 'Subject ID' and each value is a subset of the dataframe for that subject\n",
    "df_MR_dict = {group: df for group, df in df_MR_grouped}\n",
    "df_CT_dict = {group: df for group, df in df_CT_grouped}\n",
    "df_PT_dict = {group: df for group, df in df_PT_grouped}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing and Serialisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will load the dicom images and mask from the given directory\n",
    "def load_data(dicom_dir, rtstruct_dir):\n",
    "    rtstruct_dir = os.path.join(rtstruct_dir, '1-1.dcm')\n",
    "    rtstruct = RTStructBuilder.create_from(\n",
    "    dicom_series_path=dicom_dir, \n",
    "    rt_struct_path= rtstruct_dir\n",
    "    )  # Load existing RT Struct. Requires the series path and existing RT Struct path\n",
    "\n",
    "    # print(rtstruct.get_roi_names()) # view all of the ROI names from within the image\n",
    "\n",
    "    mask_3d = rtstruct.get_roi_mask_by_name(\"GTV_Mass\") # loading the 3D Mask from within the RT Struct\n",
    "\n",
    "    image_files = [os.path.join(dicom_dir, f) for f in os.listdir(dicom_dir) if f.endswith('.dcm')] # get a list of all DICOM files in the directory\n",
    "    image_files.sort(reverse=True) # sort the image_files by their name\n",
    "    images = {pydicom.dcmread(f).SOPInstanceUID: pydicom.dcmread(f) for f in image_files} # load the DICOM images\n",
    "\n",
    "    return images, mask_3d\n",
    "\n",
    "\n",
    "# this function will display the images and mask\n",
    "def view_data(images, mask_3d):\n",
    "    for i in range(mask_3d.shape[2]):\n",
    "        uid = list(images.keys())[i]  # get the SOPInstanceUID of the ith image\n",
    "\n",
    "\n",
    "        mask_slice = mask_3d[:, :, i]\n",
    "\n",
    "        # if the mask_slice dimensions are not the same as the image dimensions, crop the side with more pixels and pad the side with less pixels with zeros\n",
    "        if mask_slice.shape != images[uid].pixel_array.shape:\n",
    "            if mask_slice.shape[0] > images[uid].pixel_array.shape[0]:\n",
    "                # crop the mask_slice\n",
    "                mask_slice = mask_slice[:images[uid].pixel_array.shape[0], :]\n",
    "            elif mask_slice.shape[0] < images[uid].pixel_array.shape[0]:\n",
    "                # pad the mask_slice with zeros starting from the bottom\n",
    "                mask_slice = np.pad(mask_slice, ((0, images[uid].pixel_array.shape[0] - mask_slice.shape[0]), (0, 0)), 'constant')\n",
    "\n",
    "            if mask_slice.shape[1] > images[uid].pixel_array.shape[1]:\n",
    "                # crop the mask_slice\n",
    "                mask_slice = mask_slice[:, :images[uid].pixel_array.shape[1]]\n",
    "            elif mask_slice.shape[1] < images[uid].pixel_array.shape[1]:\n",
    "                # pad the mask_slice with zeros from the right\n",
    "                mask_slice = np.pad(mask_slice, ((0, 0), (0, images[uid].pixel_array.shape[1] - mask_slice.shape[1])), 'constant')\n",
    "\n",
    "        # Now that the mask_slice and image dimensions are the same, we can resize the dimensions of both mask_slice and image for machine learning\n",
    "        mask_slice = cv2.resize(mask_slice.astype(np.uint8), (128, 128), interpolation=cv2.INTER_NEAREST)\n",
    "        img_slice = cv2.resize(images[uid].pixel_array, (128, 128))\n",
    "\n",
    "        plt.imshow(img_slice, cmap='gray') # plot the ith image\n",
    "        plt.imshow(mask_slice, cmap='jet', alpha=0.5) # overlay the mask with transparency\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# this function will serialise the images and mask for machine learning\n",
    "def serialise_data(images, mask_3d, img_directory, mask_directory):\n",
    "    for i in range(mask_3d.shape[2]):\n",
    "        uid = list(images.keys())[i]  # get the SOPInstanceUID of the ith image\n",
    "\n",
    "        mask_slice = mask_3d[:, :, i]\n",
    "\n",
    "        # if the mask_slice dimensions are not the same as the image dimensions, crop the side with more pixels and pad the side with less pixels with zeros\n",
    "        if mask_slice.shape != images[uid].pixel_array.shape:\n",
    "            if mask_slice.shape[0] > images[uid].pixel_array.shape[0]:\n",
    "                # crop the mask_slice\n",
    "                mask_slice = mask_slice[:images[uid].pixel_array.shape[0], :]\n",
    "            elif mask_slice.shape[0] < images[uid].pixel_array.shape[0]:\n",
    "                # pad the mask_slice with zeros starting from the bottom\n",
    "                mask_slice = np.pad(mask_slice, ((0, images[uid].pixel_array.shape[0] - mask_slice.shape[0]), (0, 0)), 'constant')\n",
    "\n",
    "            if mask_slice.shape[1] > images[uid].pixel_array.shape[1]:\n",
    "                # crop the mask_slice\n",
    "                mask_slice = mask_slice[:, :images[uid].pixel_array.shape[1]]\n",
    "            elif mask_slice.shape[1] < images[uid].pixel_array.shape[1]:\n",
    "                # pad the mask_slice with zeros from the right\n",
    "                mask_slice = np.pad(mask_slice, ((0, 0), (0, images[uid].pixel_array.shape[1] - mask_slice.shape[1])), 'constant')\n",
    "\n",
    "        # Now that the mask_slice and image dimensions are the same, we can resize the dimensions of both mask_slice and image for machine learning\n",
    "        mask_slice = cv2.resize(mask_slice.astype(np.uint8), (128, 128), interpolation=cv2.INTER_NEAREST)\n",
    "        # convert mask_slice into a \n",
    "        img_slice = cv2.resize(images[uid].pixel_array, (128, 128))\n",
    "\n",
    "        # serialise the img_slice into jpg format in the img_directory\n",
    "        cv2.imwrite(os.path.join(img_directory, f'{images[uid].SeriesInstanceUID}_{i}.jpg'), img_slice)\n",
    "        # serialise the mask_slice into png format in the mask_directory\n",
    "        cv2.imwrite(os.path.join(mask_directory, f'{images[uid].SeriesInstanceUID}_{i}.png'), mask_slice*255)\n",
    "\n",
    "\n",
    "# this function will split the data into training and testing sets\n",
    "def split_data_into_train_test(dataset_dir, split_ratio=0.2):\n",
    "    # Define the sub-directories\n",
    "    image_dir = os.path.join(dataset_dir, \"train\", \"images\")\n",
    "    mask_dir = os.path.join(dataset_dir, \"train\", \"mask\")\n",
    "\n",
    "    # Get the lists of images and masks\n",
    "    images = os.listdir(image_dir)\n",
    "    masks = os.listdir(mask_dir)\n",
    "\n",
    "    # Split the datasets into training and testing sets\n",
    "    train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=split_ratio, random_state=42)\n",
    "\n",
    "    # Define the destination directories\n",
    "    test_image_dest_dir = os.path.join(dataset_dir, \"test\", \"images\")\n",
    "    test_mask_dest_dir = os.path.join(dataset_dir, \"test\", \"mask\")\n",
    "\n",
    "    # Move the testing images and masks to the testing directory\n",
    "    for img in test_images:\n",
    "        shutil.move(os.path.join(image_dir, img), test_image_dest_dir)\n",
    "\n",
    "    for mask in test_masks:\n",
    "        shutil.move(os.path.join(mask_dir, mask), test_mask_dest_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmimaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
